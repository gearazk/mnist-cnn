{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 Ti (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_val = onehot(y_val)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test,1)\n",
    "X_train = np.expand_dims(X_train,1)\n",
    "X_val = np.expand_dims(X_val,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model1():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        \n",
    "        Convolution2D(64, 3, 3, activation='elu', border_mode='same'),\n",
    "        Convolution2D(128, 3, 3, activation='elu', border_mode='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Convolution2D(128, 3, 3, activation='elu', border_mode='same'),\n",
    "        Convolution2D(128, 3, 3, activation='elu', border_mode='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Convolution2D(128, 3, 3, activation='elu', border_mode='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(1024, activation='elu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(1024, activation='elu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = get_model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 21s - loss: 1.2422 - acc: 0.6262 - val_loss: 2.0137 - val_acc: 0.2354\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.4288 - acc: 0.8644 - val_loss: 0.4043 - val_acc: 0.8778\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.2863 - acc: 0.9114 - val_loss: 0.1351 - val_acc: 0.9584\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.2221 - acc: 0.9309 - val_loss: 0.1051 - val_acc: 0.9667\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.1855 - acc: 0.9419 - val_loss: 0.0925 - val_acc: 0.9712\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.1576 - acc: 0.9512 - val_loss: 0.0807 - val_acc: 0.9748\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.1371 - acc: 0.9578 - val_loss: 0.0767 - val_acc: 0.9754\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.1179 - acc: 0.9626 - val_loss: 0.0660 - val_acc: 0.9805\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.1080 - acc: 0.9664 - val_loss: 0.0655 - val_acc: 0.9795\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 20s - loss: 0.0967 - acc: 0.9694 - val_loss: 0.0586 - val_acc: 0.9812\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0908 - acc: 0.9717 - val_loss: 0.0592 - val_acc: 0.9818\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0810 - acc: 0.9744 - val_loss: 0.0507 - val_acc: 0.9839\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0746 - acc: 0.9756 - val_loss: 0.0523 - val_acc: 0.9833\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0692 - acc: 0.9779 - val_loss: 0.0477 - val_acc: 0.9860\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0662 - acc: 0.9789 - val_loss: 0.0527 - val_acc: 0.9833\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0598 - acc: 0.9815 - val_loss: 0.0439 - val_acc: 0.9858\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0560 - acc: 0.9818 - val_loss: 0.0470 - val_acc: 0.9859\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0530 - acc: 0.9826 - val_loss: 0.0453 - val_acc: 0.9858\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0490 - acc: 0.9839 - val_loss: 0.0489 - val_acc: 0.9862\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0459 - acc: 0.9852 - val_loss: 0.0401 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff76b9b3310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(batches, batches.N, nb_epoch=20, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0440 - acc: 0.9864 - val_loss: 0.0452 - val_acc: 0.9863\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0404 - acc: 0.9868 - val_loss: 0.0441 - val_acc: 0.9875\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0386 - acc: 0.9871 - val_loss: 0.0420 - val_acc: 0.9876\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0341 - acc: 0.9887 - val_loss: 0.0417 - val_acc: 0.9885\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0333 - acc: 0.9891 - val_loss: 0.0419 - val_acc: 0.9873\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0294 - acc: 0.9902 - val_loss: 0.0417 - val_acc: 0.9881\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0298 - acc: 0.9897 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0274 - acc: 0.9910 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0254 - acc: 0.9912 - val_loss: 0.0390 - val_acc: 0.9892\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0257 - acc: 0.9913 - val_loss: 0.0428 - val_acc: 0.9890\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0223 - acc: 0.9927 - val_loss: 0.0368 - val_acc: 0.9894\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0208 - acc: 0.9931 - val_loss: 0.0398 - val_acc: 0.9894\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0207 - acc: 0.9931 - val_loss: 0.0436 - val_acc: 0.9877\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 20s - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0389 - val_acc: 0.9896\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.0191 - acc: 0.9933 - val_loss: 0.0394 - val_acc: 0.9887\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.0156 - acc: 0.9947 - val_loss: 0.0378 - val_acc: 0.9894\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 20s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0394 - val_acc: 0.9894\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0400 - val_acc: 0.9888\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0136 - acc: 0.9955 - val_loss: 0.0385 - val_acc: 0.9891\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0133 - acc: 0.9958 - val_loss: 0.0396 - val_acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff76ba4ae10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(batches, batches.N, nb_epoch=20, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0381 - val_acc: 0.9898\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0366 - val_acc: 0.9898\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 20s - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0403 - val_acc: 0.9894\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0418 - val_acc: 0.9884\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0101 - acc: 0.9965 - val_loss: 0.0358 - val_acc: 0.9906\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0419 - val_acc: 0.9896\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0387 - val_acc: 0.9889\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0372 - val_acc: 0.9903\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0341 - val_acc: 0.9904\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0439 - val_acc: 0.9892\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0394 - val_acc: 0.9898\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 22s - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0357 - val_acc: 0.9908\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 21s - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0388 - val_acc: 0.9907\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 20s - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0419 - val_acc: 0.9891\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0399 - val_acc: 0.9905\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0354 - val_acc: 0.9908\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 18s - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0361 - val_acc: 0.9914\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0429 - val_acc: 0.9898\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 19s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0393 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff76ba53ed0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(batches, batches.N, nb_epoch=20, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99309999999999998"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test, batch_size)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save_weights(path + '/weightsTr/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        \n",
    "        Convolution2D(64, 3, 3, border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Activation('elu'),\n",
    "        Convolution2D(128, 3, 3, border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Activation('elu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Convolution2D(128, 3, 3, border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Activation('elu'),\n",
    "        Convolution2D(128, 3, 3, border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Activation('elu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Convolution2D(128, 3, 3, border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Activation('elu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(1024, activation='elu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(1024, activation='elu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = get_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "48000/48000 [==============================] - 27s - loss: 1.3016 - acc: 0.6053 - val_loss: 2.6428 - val_acc: 0.2951\n",
      "Epoch 2/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.4211 - acc: 0.8654 - val_loss: 0.5274 - val_acc: 0.8469\n",
      "Epoch 3/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.2700 - acc: 0.9132 - val_loss: 0.1286 - val_acc: 0.9587\n",
      "Epoch 4/60\n",
      "48000/48000 [==============================] - 28s - loss: 0.2070 - acc: 0.9357 - val_loss: 0.0995 - val_acc: 0.9688\n",
      "Epoch 5/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.1718 - acc: 0.9461 - val_loss: 0.0850 - val_acc: 0.9730\n",
      "Epoch 6/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.1411 - acc: 0.9556 - val_loss: 0.0740 - val_acc: 0.9780\n",
      "Epoch 7/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.1266 - acc: 0.9606 - val_loss: 0.0720 - val_acc: 0.9778\n",
      "Epoch 8/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.1109 - acc: 0.9645 - val_loss: 0.0677 - val_acc: 0.9802\n",
      "Epoch 9/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0978 - acc: 0.9690 - val_loss: 0.0585 - val_acc: 0.9823\n",
      "Epoch 10/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0890 - acc: 0.9711 - val_loss: 0.0570 - val_acc: 0.9827\n",
      "Epoch 11/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0786 - acc: 0.9753 - val_loss: 0.0536 - val_acc: 0.9838\n",
      "Epoch 12/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0733 - acc: 0.9768 - val_loss: 0.0516 - val_acc: 0.9853\n",
      "Epoch 13/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0703 - acc: 0.9781 - val_loss: 0.0491 - val_acc: 0.9844\n",
      "Epoch 14/60\n",
      "48000/48000 [==============================] - 28s - loss: 0.0641 - acc: 0.9791 - val_loss: 0.0475 - val_acc: 0.9863\n",
      "Epoch 15/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0574 - acc: 0.9814 - val_loss: 0.0478 - val_acc: 0.9855\n",
      "Epoch 16/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0530 - acc: 0.9830 - val_loss: 0.0446 - val_acc: 0.9864\n",
      "Epoch 17/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0485 - acc: 0.9840 - val_loss: 0.0432 - val_acc: 0.9872\n",
      "Epoch 18/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0466 - acc: 0.9852 - val_loss: 0.0440 - val_acc: 0.9872\n",
      "Epoch 19/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0440 - acc: 0.9855 - val_loss: 0.0437 - val_acc: 0.9878\n",
      "Epoch 20/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0390 - acc: 0.9872 - val_loss: 0.0412 - val_acc: 0.9884\n",
      "Epoch 21/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0381 - acc: 0.9874 - val_loss: 0.0378 - val_acc: 0.9896\n",
      "Epoch 22/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0355 - acc: 0.9886 - val_loss: 0.0405 - val_acc: 0.9888\n",
      "Epoch 23/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0330 - acc: 0.9890 - val_loss: 0.0458 - val_acc: 0.9870\n",
      "Epoch 24/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0305 - acc: 0.9900 - val_loss: 0.0375 - val_acc: 0.9895\n",
      "Epoch 25/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0287 - acc: 0.9901 - val_loss: 0.0458 - val_acc: 0.9881\n",
      "Epoch 26/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0264 - acc: 0.9916 - val_loss: 0.0377 - val_acc: 0.9896\n",
      "Epoch 27/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0236 - acc: 0.9922 - val_loss: 0.0371 - val_acc: 0.9896\n",
      "Epoch 28/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0236 - acc: 0.9920 - val_loss: 0.0347 - val_acc: 0.9899\n",
      "Epoch 29/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0229 - acc: 0.9922 - val_loss: 0.0442 - val_acc: 0.9878\n",
      "Epoch 30/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0195 - acc: 0.9930 - val_loss: 0.0402 - val_acc: 0.9895\n",
      "Epoch 31/60\n",
      "48000/48000 [==============================] - 28s - loss: 0.0190 - acc: 0.9935 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "Epoch 32/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0375 - val_acc: 0.9908\n",
      "Epoch 33/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0163 - acc: 0.9946 - val_loss: 0.0376 - val_acc: 0.9898\n",
      "Epoch 34/60\n",
      "48000/48000 [==============================] - 31s - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0401 - val_acc: 0.9898\n",
      "Epoch 35/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0151 - acc: 0.9950 - val_loss: 0.0348 - val_acc: 0.9910\n",
      "Epoch 36/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0144 - acc: 0.9949 - val_loss: 0.0401 - val_acc: 0.9908\n",
      "Epoch 37/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0120 - acc: 0.9962 - val_loss: 0.0410 - val_acc: 0.9897\n",
      "Epoch 38/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0400 - val_acc: 0.9899\n",
      "Epoch 39/60\n",
      "48000/48000 [==============================] - 30s - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0395 - val_acc: 0.9906\n",
      "Epoch 40/60\n",
      "48000/48000 [==============================] - 31s - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0423 - val_acc: 0.9901\n",
      "Epoch 41/60\n",
      "48000/48000 [==============================] - 28s - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0375 - val_acc: 0.9911\n",
      "Epoch 42/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0411 - val_acc: 0.9902\n",
      "Epoch 43/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0374 - val_acc: 0.9906\n",
      "Epoch 44/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0447 - val_acc: 0.9894\n",
      "Epoch 45/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0353 - val_acc: 0.9913\n",
      "Epoch 46/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0407 - val_acc: 0.9912\n",
      "Epoch 47/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0398 - val_acc: 0.9900\n",
      "Epoch 48/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0402 - val_acc: 0.9912\n",
      "Epoch 49/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0351 - val_acc: 0.9917\n",
      "Epoch 50/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0419 - val_acc: 0.9904\n",
      "Epoch 51/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0466 - val_acc: 0.9903\n",
      "Epoch 52/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0365 - val_acc: 0.9920\n",
      "Epoch 53/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0368 - val_acc: 0.9908\n",
      "Epoch 54/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0388 - val_acc: 0.9903\n",
      "Epoch 55/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0390 - val_acc: 0.9914\n",
      "Epoch 56/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0421 - val_acc: 0.9908\n",
      "Epoch 57/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0385 - val_acc: 0.9914\n",
      "Epoch 58/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0390 - val_acc: 0.9917\n",
      "Epoch 59/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0413 - val_acc: 0.9907\n",
      "Epoch 60/60\n",
      "48000/48000 [==============================] - 27s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0450 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff76b9dacd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(batches, batches.N, nb_epoch=60, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9919"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test, batch_size)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save_weights(path + '/weightsTr/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        \n",
    "        Convolution2D(64, 5, 5, activation='elu', border_mode='same'),\n",
    "        Convolution2D(128, 5, 5, activation='elu', border_mode='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Convolution2D(128, 5, 5, activation='elu', border_mode='same'),\n",
    "        Convolution2D(128, 5, 5, activation='elu', border_mode='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Convolution2D(128, 5, 5, activation='elu', border_mode='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(1024, activation='elu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(1024, activation='elu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 31s - loss: 0.9833 - acc: 0.7003 - val_loss: 1.3281 - val_acc: 0.5071\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 32s - loss: 0.3345 - acc: 0.8949 - val_loss: 0.2733 - val_acc: 0.9237\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 32s - loss: 0.2253 - acc: 0.9310 - val_loss: 0.1167 - val_acc: 0.9624\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.1745 - acc: 0.9455 - val_loss: 0.0956 - val_acc: 0.9715\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.1442 - acc: 0.9547 - val_loss: 0.0834 - val_acc: 0.9739\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.1219 - acc: 0.9620 - val_loss: 0.0771 - val_acc: 0.9764\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.1052 - acc: 0.9664 - val_loss: 0.0700 - val_acc: 0.9788\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0930 - acc: 0.9708 - val_loss: 0.0646 - val_acc: 0.9803\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0817 - acc: 0.9743 - val_loss: 0.0612 - val_acc: 0.9813\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 32s - loss: 0.0732 - acc: 0.9760 - val_loss: 0.0649 - val_acc: 0.9803\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0648 - acc: 0.9792 - val_loss: 0.0563 - val_acc: 0.9831\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 31s - loss: 0.0605 - acc: 0.9804 - val_loss: 0.0543 - val_acc: 0.9829\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0513 - acc: 0.9836 - val_loss: 0.0568 - val_acc: 0.9838\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0494 - acc: 0.9839 - val_loss: 0.0487 - val_acc: 0.9858\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0442 - acc: 0.9859 - val_loss: 0.0487 - val_acc: 0.9842\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0377 - acc: 0.9879 - val_loss: 0.0477 - val_acc: 0.9856\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0361 - acc: 0.9879 - val_loss: 0.0450 - val_acc: 0.9868\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0324 - acc: 0.9892 - val_loss: 0.0458 - val_acc: 0.9864\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0300 - acc: 0.9897 - val_loss: 0.0471 - val_acc: 0.9868\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0283 - acc: 0.9902 - val_loss: 0.0439 - val_acc: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff727241910>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit_generator(batches, batches.N, nb_epoch=20, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 32s - loss: 0.0247 - acc: 0.9919 - val_loss: 0.0449 - val_acc: 0.9877\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0223 - acc: 0.9926 - val_loss: 0.0389 - val_acc: 0.9882\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 31s - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0455 - val_acc: 0.9872\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0403 - val_acc: 0.9885\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 31s - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0417 - val_acc: 0.9886\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0162 - acc: 0.9949 - val_loss: 0.0448 - val_acc: 0.9877\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0417 - val_acc: 0.9878\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0430 - val_acc: 0.9892\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0462 - val_acc: 0.9878\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0396 - val_acc: 0.9895\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0435 - val_acc: 0.9886\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0091 - acc: 0.9973 - val_loss: 0.0422 - val_acc: 0.9875\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0429 - val_acc: 0.9887\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0493 - val_acc: 0.9872\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0427 - val_acc: 0.9886\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0460 - val_acc: 0.9881\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 32s - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0434 - val_acc: 0.9893\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0448 - val_acc: 0.9892\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0430 - val_acc: 0.9881\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0464 - val_acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff733141890>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit_generator(batches, batches.N, nb_epoch=20, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0454 - val_acc: 0.9881\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0448 - val_acc: 0.9885\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0431 - val_acc: 0.9889\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0472 - val_acc: 0.9892\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 33s - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0449 - val_acc: 0.9892\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 31s - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0481 - val_acc: 0.9885\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0408 - val_acc: 0.9902\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0473 - val_acc: 0.9891\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0477 - val_acc: 0.9901\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0470 - val_acc: 0.9890\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0477 - val_acc: 0.9892\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0458 - val_acc: 0.9895\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0570 - val_acc: 0.9873\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0507 - val_acc: 0.9883\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0530 - val_acc: 0.9873\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 29s - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0434 - val_acc: 0.9902\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0501 - val_acc: 0.9892\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0503 - val_acc: 0.9894\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0425 - val_acc: 0.9903\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 30s - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0437 - val_acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff72076c8d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit_generator(batches, batches.N, nb_epoch=20, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99170000000000003"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test, batch_size)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
